const logger = require('./logger')
const memoryOptimizer = require('./memoryOptimizer')
const asyncMonitor = require('./asyncMonitor')

/**
 * æ‰¹å¤„ç† Redis æ“ä½œç®¡ç†å™¨
 * è‡ªåŠ¨æ”¶é›†å’Œæ‰¹é‡æ‰§è¡Œ Redis å‘½ä»¤ä»¥æé«˜æ€§èƒ½
 */
class BatchOperationManager {
  constructor(redisClient) {
    this.client = redisClient
    this.pendingOperations = []
    this.batchTimeout = null
    this.config = {
      maxBatchSize: 100,      // æœ€å¤§æ‰¹å¤„ç†å¤§å°
      batchDelayMs: 50,       // æ‰¹å¤„ç†å»¶è¿Ÿæ—¶é—´ï¼ˆæ¯«ç§’ï¼‰
      maxRetries: 3,          // æœ€å¤§é‡è¯•æ¬¡æ•°
      retryDelayMs: 100       // é‡è¯•å»¶è¿Ÿæ—¶é—´
    }
    this.stats = {
      totalBatches: 0,
      totalOperations: 0,
      averageBatchSize: 0,
      errors: 0,
      retries: 0
    }
    
    // åˆ›å»ºæ“ä½œå¯¹è±¡æ± 
    this.operationPool = memoryOptimizer.getObjectPool('batchOperation') || 
      memoryOptimizer.registerObjectPool(
        'batchOperation',
        () => ({
          command: '',
          args: [],
          resolve: null,
          reject: null,
          timestamp: 0
        }),
        (op) => {
          op.command = ''
          op.args.length = 0
          op.resolve = null
          op.reject = null
          op.timestamp = 0
        },
        50
      )
  }

  /**
   * æ·»åŠ  Redis æ“ä½œåˆ°æ‰¹å¤„ç†é˜Ÿåˆ—
   */
  addOperation(command, args) {
    return new Promise((resolve, reject) => {
      const operation = this.operationPool.acquire()
      operation.command = command
      operation.args = [...args]
      operation.resolve = resolve
      operation.reject = reject
      operation.timestamp = Date.now()
      
      this.pendingOperations.push(operation)
      
      // è·Ÿè¸ª Promise
      asyncMonitor.trackPromise(
        new Promise((res, rej) => {
          operation.resolve = (result) => {
            res(result)
            resolve(result)
          }
          operation.reject = (error) => {
            rej(error)
            reject(error)
          }
        }),
        {
          type: 'redis_batch_operation',
          command,
          timeout: 10000
        }
      )
      
      // æ£€æŸ¥æ˜¯å¦éœ€è¦ç«‹å³æ‰§è¡Œæ‰¹å¤„ç†
      if (this.pendingOperations.length >= this.config.maxBatchSize) {
        this.executeBatch()
      } else if (!this.batchTimeout) {
        // è®¾ç½®å»¶è¿Ÿæ‰¹å¤„ç†
        this.batchTimeout = setTimeout(() => {
          this.executeBatch()
        }, this.config.batchDelayMs)
      }
    })
  }

  /**
   * æ‰§è¡Œæ‰¹å¤„ç†æ“ä½œ
   */
  async executeBatch(retryCount = 0) {
    if (this.pendingOperations.length === 0) {
      return
    }
    
    // æ¸…é™¤è¶…æ—¶å®šæ—¶å™¨
    if (this.batchTimeout) {
      clearTimeout(this.batchTimeout)
      this.batchTimeout = null
    }
    
    const operations = [...this.pendingOperations]
    this.pendingOperations.length = 0
    
    try {
      const pipeline = this.client.pipeline()
      
      // æ·»åŠ æ‰€æœ‰æ“ä½œåˆ° pipeline
      operations.forEach(op => {
        pipeline[op.command](...op.args)
      })
      
      // æ‰§è¡Œ pipeline
      const results = await pipeline.exec()
      
      // å¤„ç†ç»“æœ
      this.processResults(operations, results)
      
      // æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
      this.updateStats(operations.length, true)
      
      logger.debug(`ğŸ“¦ Executed Redis batch: ${operations.length} operations`)
      
    } catch (error) {
      logger.error('âŒ Redis batch execution failed:', error)
      
      // é‡è¯•é€»è¾‘
      if (retryCount < this.config.maxRetries) {
        this.stats.retries++
        logger.warn(`ğŸ”„ Retrying Redis batch (attempt ${retryCount + 1}/${this.config.maxRetries})`)
        
        // å»¶è¿Ÿé‡è¯•
        setTimeout(() => {
          // å°†æ“ä½œé‡æ–°æ·»åŠ åˆ°é˜Ÿåˆ—
          this.pendingOperations.unshift(...operations)
          this.executeBatch(retryCount + 1)
        }, this.config.retryDelayMs * Math.pow(2, retryCount))
        
      } else {
        // é‡è¯•å¤±è´¥ï¼Œæ‹’ç»æ‰€æœ‰æ“ä½œ
        operations.forEach(op => {
          if (op.reject) {
            op.reject(error)
          }
          if (op._poolRelease) {
            op._poolRelease()
          }
        })
        
        this.updateStats(operations.length, false)
      }
    }
  }

  /**
   * å¤„ç†æ‰¹å¤„ç†ç»“æœ
   */
  processResults(operations, results) {
    operations.forEach((op, index) => {
      try {
        const [error, result] = results[index]
        
        if (error) {
          if (op.reject) {
            op.reject(error)
          }
        } else {
          if (op.resolve) {
            op.resolve(result)
          }
        }
        
        // é‡Šæ”¾æ“ä½œå¯¹è±¡å›æ± 
        if (op._poolRelease) {
          op._poolRelease()
        }
        
      } catch (processError) {
        logger.error(`âŒ Error processing batch result ${index}:`, processError)
        
        if (op.reject) {
          op.reject(processError)
        }
        
        if (op._poolRelease) {
          op._poolRelease()
        }
      }
    })
  }

  /**
   * æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
   */
  updateStats(operationCount, success) {
    this.stats.totalBatches++
    this.stats.totalOperations += operationCount
    
    if (!success) {
      this.stats.errors++
    }
    
    // è®¡ç®—å¹³å‡æ‰¹å¤„ç†å¤§å°
    this.stats.averageBatchSize = this.stats.totalOperations / this.stats.totalBatches
  }

  /**
   * å¼ºåˆ¶æ‰§è¡Œæ‰€æœ‰å¾…å¤„ç†æ“ä½œ
   */
  async flush() {
    if (this.pendingOperations.length > 0) {
      await this.executeBatch()
    }
  }

  /**
   * è·å–ç»Ÿè®¡ä¿¡æ¯
   */
  getStats() {
    return {
      ...this.stats,
      pendingOperations: this.pendingOperations.length,
      config: { ...this.config }
    }
  }

  /**
   * é…ç½®æ‰¹å¤„ç†å‚æ•°
   */
  configure(newConfig) {
    this.config = { ...this.config, ...newConfig }
    logger.info('âš™ï¸ Redis batch manager configured:', this.config)
  }

  /**
   * æ¸…ç†èµ„æº
   */
  cleanup() {
    if (this.batchTimeout) {
      clearTimeout(this.batchTimeout)
      this.batchTimeout = null
    }
    
    // æ‹’ç»æ‰€æœ‰å¾…å¤„ç†æ“ä½œ
    this.pendingOperations.forEach(op => {
      if (op.reject) {
        op.reject(new Error('Batch manager is shutting down'))
      }
      if (op._poolRelease) {
        op._poolRelease()
      }
    })
    
    this.pendingOperations.length = 0
    
    logger.info('ğŸ§¹ Redis batch manager cleaned up')
  }
}

/**
 * æ™ºèƒ½ Redis Pipeline ä¼˜åŒ–å™¨
 * æä¾›é«˜çº§çš„ Pipeline ç®¡ç†å’Œä¼˜åŒ–åŠŸèƒ½
 */
class OptimizedRedisPipeline {
  constructor(redisClient) {
    this.client = redisClient
    this.batchManager = new BatchOperationManager(redisClient)
    
    // æ™ºèƒ½ Pipeline é…ç½®
    this.config = {
      enableBatching: true,           // å¯ç”¨æ‰¹å¤„ç†
      enableIntelligentDelay: true,   // å¯ç”¨æ™ºèƒ½å»¶è¿Ÿ
      enableCompression: false,       // å¯ç”¨æ•°æ®å‹ç¼©
      maxPipelineSize: 1000,         // æœ€å¤§ Pipeline å¤§å°
      intelligentDelayThreshold: 10,  // æ™ºèƒ½å»¶è¿Ÿé˜ˆå€¼
      compressionThreshold: 1024      // å‹ç¼©é˜ˆå€¼ï¼ˆå­—èŠ‚ï¼‰
    }
    
    this.stats = {
      totalPipelines: 0,
      totalCommands: 0,
      savedRoundTrips: 0,
      compressionSavings: 0
    }
  }

  /**
   * åˆ›å»ºä¼˜åŒ–çš„ Pipeline
   */
  createPipeline() {
    return new OptimizedPipeline(this.client, this.config, this.stats)
  }

  /**
   * æ‰¹å¤„ç†æ“ä½œï¼ˆè‡ªåŠ¨ä¼˜åŒ–ï¼‰
   */
  async batch(operations) {
    if (!this.config.enableBatching) {
      // å¦‚æœç¦ç”¨æ‰¹å¤„ç†ï¼Œä½¿ç”¨ä¼ ç»Ÿ Pipeline
      return this.executePipeline(operations)
    }
    
    // ä½¿ç”¨æ‰¹å¤„ç†ç®¡ç†å™¨
    const promises = operations.map(op => {
      const { command, args } = op
      return this.batchManager.addOperation(command, args || [])
    })
    
    return Promise.all(promises)
  }

  /**
   * æ‰§è¡Œä¼ ç»Ÿ Pipeline
   */
  async executePipeline(operations) {
    const pipeline = this.client.pipeline()
    
    operations.forEach(op => {
      const { command, args } = op
      pipeline[command](...(args || []))
    })
    
    const results = await pipeline.exec()
    this.stats.totalPipelines++
    this.stats.totalCommands += operations.length
    
    return results.map(([error, result]) => {
      if (error) throw error
      return result
    })
  }

  /**
   * æ™ºèƒ½æ‰¹å¤„ç†ç»Ÿè®¡æ“ä½œ
   * ä¸“é—¨ä¼˜åŒ–ä½¿ç”¨ç»Ÿè®¡ç›¸å…³çš„ Redis æ“ä½œ
   */
  async batchUsageStats(operations) {
    // æŒ‰é”®åˆ†ç»„æ“ä½œï¼Œå‡å°‘å‘½ä»¤æ•°é‡
    const groupedOps = this.groupOperationsByKey(operations)
    
    // ä½¿ç”¨æ‰¹å¤„ç†ç®¡ç†å™¨æ‰§è¡Œåˆ†ç»„æ“ä½œ
    const promises = []
    
    for (const [key, ops] of groupedOps) {
      // åˆå¹¶åŒç±»æ“ä½œ
      const mergedOps = this.mergeOperations(ops)
      
      for (const op of mergedOps) {
        promises.push(
          this.batchManager.addOperation(op.command, [key, ...op.args])
        )
      }
    }
    
    return Promise.all(promises)
  }

  /**
   * æŒ‰é”®åˆ†ç»„æ“ä½œ
   */
  groupOperationsByKey(operations) {
    const grouped = new Map()
    
    operations.forEach(op => {
      const key = op.key
      if (!grouped.has(key)) {
        grouped.set(key, [])
      }
      grouped.get(key).push(op)
    })
    
    return grouped
  }

  /**
   * åˆå¹¶åŒç±»æ“ä½œ
   */
  mergeOperations(operations) {
    const merged = new Map()
    
    operations.forEach(op => {
      const { command, field, value } = op
      const opKey = `${command}:${field}`
      
      if (command === 'hincrby' && merged.has(opKey)) {
        // åˆå¹¶ hincrby æ“ä½œ
        merged.get(opKey).args[1] += value
      } else {
        merged.set(opKey, {
          command,
          args: field ? [field, value] : [value]
        })
      }
    })
    
    return Array.from(merged.values())
  }

  /**
   * è·å–å®Œæ•´ç»Ÿè®¡ä¿¡æ¯
   */
  getStats() {
    return {
      pipeline: { ...this.stats },
      batch: this.batchManager.getStats(),
      config: { ...this.config }
    }
  }

  /**
   * é…ç½®ä¼˜åŒ–å™¨
   */
  configure(newConfig) {
    this.config = { ...this.config, ...newConfig }
    
    // é…ç½®æ‰¹å¤„ç†ç®¡ç†å™¨
    if (newConfig.batchConfig) {
      this.batchManager.configure(newConfig.batchConfig)
    }
    
    logger.info('âš™ï¸ Redis pipeline optimizer configured:', this.config)
  }

  /**
   * å¼ºåˆ¶åˆ·æ–°æ‰€æœ‰å¾…å¤„ç†æ“ä½œ
   */
  async flush() {
    await this.batchManager.flush()
  }

  /**
   * æ¸…ç†èµ„æº
   */
  cleanup() {
    this.batchManager.cleanup()
    logger.info('ğŸ§¹ Redis pipeline optimizer cleaned up')
  }
}

/**
 * ä¼˜åŒ–çš„ Pipeline å®ä¾‹
 */
class OptimizedPipeline {
  constructor(client, config, stats) {
    this.client = client
    this.config = config
    this.stats = stats
    this.pipeline = client.pipeline()
    this.commandCount = 0
    
    // ä½¿ç”¨å¯¹è±¡æ± ç®¡ç†å‘½ä»¤
    this.bufferPool = memoryOptimizer.getBufferPool()
  }

  /**
   * æ·»åŠ å‘½ä»¤åˆ° Pipeline
   */
  addCommand(command, ...args) {
    this.pipeline[command](...args)
    this.commandCount++
    
    // æ£€æŸ¥æ˜¯å¦è¶…è¿‡æœ€å¤§ Pipeline å¤§å°
    if (this.commandCount >= this.config.maxPipelineSize) {
      logger.warn(`âš ï¸ Pipeline size limit reached: ${this.commandCount}`)
    }
    
    return this
  }

  /**
   * æ‰§è¡Œ Pipeline
   */
  async exec() {
    if (this.commandCount === 0) {
      return []
    }
    
    try {
      const startTime = Date.now()
      const results = await this.pipeline.exec()
      const duration = Date.now() - startTime
      
      // æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
      this.stats.totalPipelines++
      this.stats.totalCommands += this.commandCount
      this.stats.savedRoundTrips += Math.max(0, this.commandCount - 1)
      
      logger.debug(`ğŸ“Š Pipeline executed: ${this.commandCount} commands in ${duration}ms`)
      
      return results
      
    } catch (error) {
      logger.error('âŒ Pipeline execution failed:', error)
      throw error
    }
  }

  /**
   * è·å–å‘½ä»¤æ•°é‡
   */
  getCommandCount() {
    return this.commandCount
  }
}

module.exports = OptimizedRedisPipeline